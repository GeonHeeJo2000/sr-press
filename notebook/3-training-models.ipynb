{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_path: /home/uoscisai/Experiments/Football/sr-press\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "base_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "print(f\"base_path: {base_path}\")\n",
    "sys.path.append(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from xgboost import XGBClassifier\n",
    "from gplearn.genetic import SymbolicClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from express.databases import SQLiteDatabase\n",
    "from express.datasets import PressingDataset\n",
    "from express.components import press\n",
    "from express.visualization import plot_action\n",
    "from express.utils import add_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_db: <express.databases.sqlite.SQLiteDatabase object at 0x773aea767790>\n",
      "test_db: <express.databases.sqlite.SQLiteDatabase object at 0x773aea767610>\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DB_PATH = os.path.join(base_path, \"stores/train_database.sqlite\")\n",
    "TEST_DB_PATH = os.path.join(base_path, \"stores/test_database.sqlite\")\n",
    "\n",
    "train_db = SQLiteDatabase(TRAIN_DB_PATH)\n",
    "test_db = SQLiteDatabase(TEST_DB_PATH)\n",
    "\n",
    "print(\"train_db:\", train_db)\n",
    "print(\"test_db:\", test_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_train: functools.partial(<class 'express.datasets.PressingDataset'>, path='/home/uoscisai/Experiments/Football/sr-press/stores/datasets/train')\n",
      "dataset_test: functools.partial(<class 'express.datasets.PressingDataset'>, path='/home/uoscisai/Experiments/Football/sr-press/stores/datasets/test')\n"
     ]
    }
   ],
   "source": [
    "dataset_train = partial(PressingDataset, path=os.path.join(base_path, \"stores\", \"datasets\", \"train\"))\n",
    "dataset_test = partial(PressingDataset, path=os.path.join(base_path, \"stores\", \"datasets\", \"test\"))\n",
    "\n",
    "print(\"dataset_train:\", dataset_train)\n",
    "print(\"dataset_test:\", dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DataSet: (12406, 195)\n",
      "Test Dataset: {(False,): 9954, (True,): 2452}\n"
     ]
    }
   ],
   "source": [
    "# xgboost, symbolic_regression\n",
    "train_dataset = PressingDataset(\n",
    "    path= os.path.join(base_path, \"stores\", \"datasets\", \"train\"),\n",
    "    xfns=[\"startlocation\", \"closest_11_players\"],\n",
    "    yfns=[\"counterpress\"],\n",
    "    load_cached=True,\n",
    "    nb_prev_actions=3\n",
    ")\n",
    "\n",
    "test_dataset = PressingDataset(\n",
    "    path= os.path.join(base_path, \"stores\", \"datasets\", \"test\"),\n",
    "    xfns=[\"startlocation\", \"closest_11_players\"],\n",
    "    yfns=[\"counterpress\"],\n",
    "    load_cached=True,\n",
    "    nb_prev_actions=3\n",
    ")\n",
    "\n",
    "# soccermap\n",
    "# test_dataset = PressingDataset(\n",
    "#     path= os.path.join(base_path, \"stores\", \"datasets\", \"test\"),\n",
    "#     xfns=[\"startlocation\", \"freeze_frame_360\"],\n",
    "#     yfns=[\"counterpress\"],\n",
    "#     load_cached=True,\n",
    "#     nb_prev_actions=1\n",
    "# )\n",
    "\n",
    "print(f\"Test DataSet: {test_dataset.features.shape}\")\n",
    "print(f\"Test Dataset: {test_dataset.labels.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'startlocation': ['start_x_a0',\n",
       "  'start_y_a0',\n",
       "  'start_x_a1',\n",
       "  'start_y_a1',\n",
       "  'start_x_a2',\n",
       "  'start_y_a2'],\n",
       " 'closest_11_players': ['teammate_1_x_a0',\n",
       "  'teammate_1_y_a0',\n",
       "  'teammate_1_distance_a0',\n",
       "  'teammate_2_x_a0',\n",
       "  'teammate_2_y_a0',\n",
       "  'teammate_2_distance_a0',\n",
       "  'teammate_3_x_a0',\n",
       "  'teammate_3_y_a0',\n",
       "  'teammate_3_distance_a0',\n",
       "  'teammate_4_x_a0',\n",
       "  'teammate_4_y_a0',\n",
       "  'teammate_4_distance_a0',\n",
       "  'teammate_5_x_a0',\n",
       "  'teammate_5_y_a0',\n",
       "  'teammate_5_distance_a0',\n",
       "  'teammate_6_x_a0',\n",
       "  'teammate_6_y_a0',\n",
       "  'teammate_6_distance_a0',\n",
       "  'teammate_7_x_a0',\n",
       "  'teammate_7_y_a0',\n",
       "  'teammate_7_distance_a0',\n",
       "  'teammate_8_x_a0',\n",
       "  'teammate_8_y_a0',\n",
       "  'teammate_8_distance_a0',\n",
       "  'teammate_9_x_a0',\n",
       "  'teammate_9_y_a0',\n",
       "  'teammate_9_distance_a0',\n",
       "  'teammate_10_x_a0',\n",
       "  'teammate_10_y_a0',\n",
       "  'teammate_10_distance_a0',\n",
       "  'opponent_1_x_a0',\n",
       "  'opponent_1_y_a0',\n",
       "  'opponent_1_distance_a0',\n",
       "  'opponent_2_x_a0',\n",
       "  'opponent_2_y_a0',\n",
       "  'opponent_2_distance_a0',\n",
       "  'opponent_3_x_a0',\n",
       "  'opponent_3_y_a0',\n",
       "  'opponent_3_distance_a0',\n",
       "  'opponent_4_x_a0',\n",
       "  'opponent_4_y_a0',\n",
       "  'opponent_4_distance_a0',\n",
       "  'opponent_5_x_a0',\n",
       "  'opponent_5_y_a0',\n",
       "  'opponent_5_distance_a0',\n",
       "  'opponent_6_x_a0',\n",
       "  'opponent_6_y_a0',\n",
       "  'opponent_6_distance_a0',\n",
       "  'opponent_7_x_a0',\n",
       "  'opponent_7_y_a0',\n",
       "  'opponent_7_distance_a0',\n",
       "  'opponent_8_x_a0',\n",
       "  'opponent_8_y_a0',\n",
       "  'opponent_8_distance_a0',\n",
       "  'opponent_9_x_a0',\n",
       "  'opponent_9_y_a0',\n",
       "  'opponent_9_distance_a0',\n",
       "  'opponent_10_x_a0',\n",
       "  'opponent_10_y_a0',\n",
       "  'opponent_10_distance_a0',\n",
       "  'opponent_11_x_a0',\n",
       "  'opponent_11_y_a0',\n",
       "  'opponent_11_distance_a0',\n",
       "  'teammate_1_x_a1',\n",
       "  'teammate_1_y_a1',\n",
       "  'teammate_1_distance_a1',\n",
       "  'teammate_2_x_a1',\n",
       "  'teammate_2_y_a1',\n",
       "  'teammate_2_distance_a1',\n",
       "  'teammate_3_x_a1',\n",
       "  'teammate_3_y_a1',\n",
       "  'teammate_3_distance_a1',\n",
       "  'teammate_4_x_a1',\n",
       "  'teammate_4_y_a1',\n",
       "  'teammate_4_distance_a1',\n",
       "  'teammate_5_x_a1',\n",
       "  'teammate_5_y_a1',\n",
       "  'teammate_5_distance_a1',\n",
       "  'teammate_6_x_a1',\n",
       "  'teammate_6_y_a1',\n",
       "  'teammate_6_distance_a1',\n",
       "  'teammate_7_x_a1',\n",
       "  'teammate_7_y_a1',\n",
       "  'teammate_7_distance_a1',\n",
       "  'teammate_8_x_a1',\n",
       "  'teammate_8_y_a1',\n",
       "  'teammate_8_distance_a1',\n",
       "  'teammate_9_x_a1',\n",
       "  'teammate_9_y_a1',\n",
       "  'teammate_9_distance_a1',\n",
       "  'teammate_10_x_a1',\n",
       "  'teammate_10_y_a1',\n",
       "  'teammate_10_distance_a1',\n",
       "  'opponent_1_x_a1',\n",
       "  'opponent_1_y_a1',\n",
       "  'opponent_1_distance_a1',\n",
       "  'opponent_2_x_a1',\n",
       "  'opponent_2_y_a1',\n",
       "  'opponent_2_distance_a1',\n",
       "  'opponent_3_x_a1',\n",
       "  'opponent_3_y_a1',\n",
       "  'opponent_3_distance_a1',\n",
       "  'opponent_4_x_a1',\n",
       "  'opponent_4_y_a1',\n",
       "  'opponent_4_distance_a1',\n",
       "  'opponent_5_x_a1',\n",
       "  'opponent_5_y_a1',\n",
       "  'opponent_5_distance_a1',\n",
       "  'opponent_6_x_a1',\n",
       "  'opponent_6_y_a1',\n",
       "  'opponent_6_distance_a1',\n",
       "  'opponent_7_x_a1',\n",
       "  'opponent_7_y_a1',\n",
       "  'opponent_7_distance_a1',\n",
       "  'opponent_8_x_a1',\n",
       "  'opponent_8_y_a1',\n",
       "  'opponent_8_distance_a1',\n",
       "  'opponent_9_x_a1',\n",
       "  'opponent_9_y_a1',\n",
       "  'opponent_9_distance_a1',\n",
       "  'opponent_10_x_a1',\n",
       "  'opponent_10_y_a1',\n",
       "  'opponent_10_distance_a1',\n",
       "  'opponent_11_x_a1',\n",
       "  'opponent_11_y_a1',\n",
       "  'opponent_11_distance_a1',\n",
       "  'teammate_1_x_a2',\n",
       "  'teammate_1_y_a2',\n",
       "  'teammate_1_distance_a2',\n",
       "  'teammate_2_x_a2',\n",
       "  'teammate_2_y_a2',\n",
       "  'teammate_2_distance_a2',\n",
       "  'teammate_3_x_a2',\n",
       "  'teammate_3_y_a2',\n",
       "  'teammate_3_distance_a2',\n",
       "  'teammate_4_x_a2',\n",
       "  'teammate_4_y_a2',\n",
       "  'teammate_4_distance_a2',\n",
       "  'teammate_5_x_a2',\n",
       "  'teammate_5_y_a2',\n",
       "  'teammate_5_distance_a2',\n",
       "  'teammate_6_x_a2',\n",
       "  'teammate_6_y_a2',\n",
       "  'teammate_6_distance_a2',\n",
       "  'teammate_7_x_a2',\n",
       "  'teammate_7_y_a2',\n",
       "  'teammate_7_distance_a2',\n",
       "  'teammate_8_x_a2',\n",
       "  'teammate_8_y_a2',\n",
       "  'teammate_8_distance_a2',\n",
       "  'teammate_9_x_a2',\n",
       "  'teammate_9_y_a2',\n",
       "  'teammate_9_distance_a2',\n",
       "  'teammate_10_x_a2',\n",
       "  'teammate_10_y_a2',\n",
       "  'teammate_10_distance_a2',\n",
       "  'opponent_1_x_a2',\n",
       "  'opponent_1_y_a2',\n",
       "  'opponent_1_distance_a2',\n",
       "  'opponent_2_x_a2',\n",
       "  'opponent_2_y_a2',\n",
       "  'opponent_2_distance_a2',\n",
       "  'opponent_3_x_a2',\n",
       "  'opponent_3_y_a2',\n",
       "  'opponent_3_distance_a2',\n",
       "  'opponent_4_x_a2',\n",
       "  'opponent_4_y_a2',\n",
       "  'opponent_4_distance_a2',\n",
       "  'opponent_5_x_a2',\n",
       "  'opponent_5_y_a2',\n",
       "  'opponent_5_distance_a2',\n",
       "  'opponent_6_x_a2',\n",
       "  'opponent_6_y_a2',\n",
       "  'opponent_6_distance_a2',\n",
       "  'opponent_7_x_a2',\n",
       "  'opponent_7_y_a2',\n",
       "  'opponent_7_distance_a2',\n",
       "  'opponent_8_x_a2',\n",
       "  'opponent_8_y_a2',\n",
       "  'opponent_8_distance_a2',\n",
       "  'opponent_9_x_a2',\n",
       "  'opponent_9_y_a2',\n",
       "  'opponent_9_distance_a2',\n",
       "  'opponent_10_x_a2',\n",
       "  'opponent_10_y_a2',\n",
       "  'opponent_10_distance_a2',\n",
       "  'opponent_11_x_a2',\n",
       "  'opponent_11_y_a2',\n",
       "  'opponent_11_distance_a2']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_prev_actions_lst = [\"0\", \"1\", \"2\"] # current(0), previous(1), second_previous(2)\n",
    "selected_features = [\"startlocation\", \"closest_11_players\"]\n",
    "features = {}\n",
    "label = [\"counterpress\"]\n",
    "\n",
    "for xfn in train_dataset.xfns.items():\n",
    "    key = xfn[0].__name__\n",
    "    values = xfn[1]\n",
    "\n",
    "    if key in selected_features:\n",
    "        features[key] = [value for value in values if value[-1:] in nb_prev_actions_lst]\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'scikit'\n",
    "\n",
    "params = {}\n",
    "\n",
    "with open(\"../params.json\", 'r') as f:\n",
    "    all_params = json.load(f)\n",
    "    params = all_params.get(model, {}) # get model's parameter\n",
    "\n",
    "params['save_path'] = path= os.path.join(base_path, \"stores\", \"model\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "xgb=XGBClassifier(\n",
    "    objective=\"binary:logistic\", \n",
    "    eval_metric='logloss' #\"auc\"\n",
    "    # you probably want to do some hyperparameter tuning here to get a good model\n",
    ")\n",
    "xgb=XGBClassifier(\n",
    "    n_estimators=100, max_depth=5, n_jobs=-1, verbosity=0, eval_metric=\"logloss\"\n",
    ")\n",
    "\n",
    "model = press.XGBoostComponent(\n",
    "    model = xgb,\n",
    "    features = features,\n",
    "    label = label,\n",
    "    params=params\n",
    ")\n",
    "\n",
    "model.train(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m press\u001b[38;5;241m.\u001b[39mScikitComponent(\n\u001b[1;32m      2\u001b[0m     model \u001b[38;5;241m=\u001b[39m logreg,\n\u001b[1;32m      3\u001b[0m     features \u001b[38;5;241m=\u001b[39m features,\n\u001b[1;32m      4\u001b[0m     label \u001b[38;5;241m=\u001b[39m label,\n\u001b[1;32m      5\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(dataset_train)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m########## Train Metrics ##########\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m########## Test Metrics ##########\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mtest(dataset_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Experiments/Football/sr-press/express/components/base.py:133\u001b[0m, in \u001b[0;36mexpressScikitComponent.test\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    131\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize_dataset(dataset)\n\u001b[1;32m    132\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mfeatures, data\u001b[38;5;241m.\u001b[39mlabels\n\u001b[0;32m--> 133\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metrics(y_test, y_hat)\n",
      "File \u001b[0;32m~/venv310/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1431\u001b[0m, in \u001b[0;36mLogisticRegression.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1423\u001b[0m ovr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1425\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     )\n\u001b[1;32m   1429\u001b[0m )\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ovr:\n\u001b[0;32m-> 1431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_proba_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1433\u001b[0m     decision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n",
      "File \u001b[0;32m~/venv310/lib/python3.10/site-packages/sklearn/linear_model/_base.py:397\u001b[0m, in \u001b[0;36mLinearClassifierMixin._predict_proba_lr\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict_proba_lr\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    391\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Probability estimation for OvR logistic regression.\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \n\u001b[1;32m    393\u001b[0m \u001b[38;5;124;03m    Positive class probabilities are computed as\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;124;03m    1. / (1. + np.exp(-self.decision_function(X)));\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;124;03m    multiclass is handled by normalizing that over all classes.\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 397\u001b[0m     prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m     expit(prob, out\u001b[38;5;241m=\u001b[39mprob)\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prob\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/venv310/lib/python3.10/site-packages/sklearn/linear_model/_base.py:363\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    360\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    361\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 363\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/venv310/lib/python3.10/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/venv310/lib/python3.10/site-packages/sklearn/utils/validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/venv310/lib/python3.10/site-packages/sklearn/utils/validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv310/lib/python3.10/site-packages/sklearn/utils/validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m     )\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "model = press.ScikitComponent(\n",
    "    model = logreg,\n",
    "    features = features,\n",
    "    label = label,\n",
    "    params=params\n",
    ")\n",
    "\n",
    "model.train(dataset_train)\n",
    "\n",
    "print(f\"########## Train Metrics ##########\\n{model.test(dataset_train)}\\n\")\n",
    "print(f\"########## Test Metrics ##########\\n{model.test(dataset_test)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from torchmetrics.classification import BinaryCalibrationError\n",
    "\n",
    "def plot_calibration_curves(y_true, y_pred, ax):\n",
    "    bce_l1 = BinaryCalibrationError(n_bins=10, norm='l1')\n",
    "    ece = bce_l1(torch.Tensor(y_pred), torch.Tensor(y_true))\n",
    "\n",
    "    prob_true, prob_pred = calibration_curve(y_true, y_pred, n_bins=10)\n",
    "    ax.plot(prob_pred, prob_true, marker='o', label=f'{model} (ECE = {ece:.4f})')\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', color='grey', label='Perfect Calibration')\n",
    "    ax.set_xlabel('Predicted Probability')\n",
    "    ax.set_ylabel('True Probability')\n",
    "    ax.set_title('Calibration Plot')\n",
    "    ax.legend()\n",
    "\n",
    "def plot_roc_curves(y_true, y_pred, ax):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    auc_score = roc_auc_score(y_true, y_pred)\n",
    "    ax.plot(fpr, tpr, label=f'{model} (AUC = {auc_score:.4f})')\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', color='grey')\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('ROC Curve')\n",
    "    ax.legend(loc='lower right')\n",
    "\n",
    "\n",
    "y_pred = component.predict(dataset_test).values\n",
    "y_true = test_dataset.labels[\"counterpress\"].values\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "plot_calibration_curves(y_true, y_pred, axes[0])\n",
    "plot_roc_curves(y_true, y_pred, axes[1])\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20  # 원하는 k 값을 설정하세요 (상위 k개)\n",
    "\n",
    "features = [col for _, cols in component.features.items() for col in cols]\n",
    "importances = component.model.feature_importances_\n",
    "indices = np.argsort(importances)[-k:]\n",
    "\n",
    "plt.figure(figsize=(max(10, k * 0.5), 10))  \n",
    "plt.barh(range(k), importances[indices], align='center')\n",
    "plt.yticks(range(k), [features[i] for i in indices])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_id = 3788741\n",
    "\n",
    "df_actions = add_names(train_db.actions(game_id)).reset_index()\n",
    "df_actions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure_idx = df_actions[df_actions[\"type_name\"] == \"pressing\"].index[5]\n",
    "home_team_id, away_team_id = train_db.get_home_away_team_id(game_id = 3788741)\n",
    "for idx in range(pressure_idx-2, pressure_idx+2):\n",
    "    if df_actions.loc[idx][\"freeze_frame_360\"] is None:\n",
    "        print(\"Skip action due to missing freeze frame\")\n",
    "        continue\n",
    "    plot_action(df_actions.loc[idx], home_team_id=home_team_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
